Note! You will need tensorflow-gpu version 2.8.0 or higher. Your version is 2.8.0
C:\Users\alexd\.conda\envs\tf-gpu\python.exe
Found 58085 files belonging to 1 classes.
Using 40660 files for training.
Found 58085 files belonging to 1 classes.
Using 17425 files for validation.
Wall time: 13.3 s
(64, 360, 240, 3)
WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x00000211A5137C10> and will run it as-is.
Cause: could not parse the source code of <function <lambda> at 0x00000211A5137C10>: no matching AST found among candidates:
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
WARNING: AutoGraph could not transform <function <lambda> at 0x00000211A5137C10> and will run it as-is.
Cause: could not parse the source code of <function <lambda> at 0x00000211A5137C10>: no matching AST found among candidates:
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
<MapDataset element_spec=TensorSpec(shape=(None, 360, 240, 3), dtype=tf.float32, name=None)>
(64, 360, 240, 3)
In range between:  0.0  and:  1.0
Wall time: 36min 38s
Generating DCGAN model.
Adding Dense...
Adding Batch Normalization...
Adding Leaky ReLU...
Reshape...
(None, 45, 30, 256)
Adding Convolution...
(None, 45, 30, 128)
Adding 2nd Batch Normalization...
Adding 2nd Leaky ReLU...
Adding 2nd Convolution...
(None, 90, 60, 64)
Adding 3rd Batch Normalization...
Adding 3rd Leaky ReLU...
Adding 3rd Convolution...
(None, 180, 120, 32)
Adding 4th Batch Normalization...
Adding 4th Leaky ReLU...
Adding 4th Convolution...
(None, 360, 240, 3)
DCGAN model completed
(1, 360, 240, 3)
Wall time: 13.5 s
DCGAN descriminator model
Adding Convolutional...
Adding Leaky Relu...
Adding 2nd Convolutional...
Adding 2nd Leaky Relu...
Adding 3rd Convolutional...
Adding 3rd Leaky Relu...
Adding 4th Convolutional...
Adding 4th Leaky Relu...
Adding Flatten...
Adding Dense...
(None, 1)
DCGAN descriminator Completed!!
tf.Tensor([[9.1677444e-05]], shape=(1, 1), dtype=float32)
Training Start...
Epoch : 0
Training step
generator.trainable_variables : [<tf.Variable 'dense/kernel:0' shape=(100, 345600) dtype=float32>, <tf.Variable 'batch_normalization/gamma:0' shape=(345600,) dtype=float32>, <tf.Variable 'batch_normalization/beta:0' shape=(345600,) dtype=float32>, <tf.Variable 'conv2d_transpose/kernel:0' shape=(5, 5, 128, 256) dtype=float32>, <tf.Variable 'batch_normalization_1/gamma:0' shape=(128,) dtype=float32>, <tf.Variable 'batch_normalization_1/beta:0' shape=(128,) dtype=float32>, <tf.Variable 'conv2d_transpose_1/kernel:0' shape=(5, 5, 64, 128) dtype=float32>, <tf.Variable 'batch_normalization_2/gamma:0' shape=(64,) dtype=float32>, <tf.Variable 'batch_normalization_2/beta:0' shape=(64,) dtype=float32>, <tf.Variable 'conv2d_transpose_2/kernel:0' shape=(5, 5, 32, 64) dtype=float32>, <tf.Variable 'batch_normalization_3/gamma:0' shape=(32,) dtype=float32>, <tf.Variable 'batch_normalization_3/beta:0' shape=(32,) dtype=float32>, <tf.Variable 'conv2d_transpose_3/kernel:0' shape=(5, 5, 3, 32) dtype=float32>]
Training step
generator.trainable_variables : [<tf.Variable 'dense/kernel:0' shape=(100, 345600) dtype=float32>, <tf.Variable 'batch_normalization/gamma:0' shape=(345600,) dtype=float32>, <tf.Variable 'batch_normalization/beta:0' shape=(345600,) dtype=float32>, <tf.Variable 'conv2d_transpose/kernel:0' shape=(5, 5, 128, 256) dtype=float32>, <tf.Variable 'batch_normalization_1/gamma:0' shape=(128,) dtype=float32>, <tf.Variable 'batch_normalization_1/beta:0' shape=(128,) dtype=float32>, <tf.Variable 'conv2d_transpose_1/kernel:0' shape=(5, 5, 64, 128) dtype=float32>, <tf.Variable 'batch_normalization_2/gamma:0' shape=(64,) dtype=float32>, <tf.Variable 'batch_normalization_2/beta:0' shape=(64,) dtype=float32>, <tf.Variable 'conv2d_transpose_2/kernel:0' shape=(5, 5, 32, 64) dtype=float32>, <tf.Variable 'batch_normalization_3/gamma:0' shape=(32,) dtype=float32>, <tf.Variable 'batch_normalization_3/beta:0' shape=(32,) dtype=float32>, <tf.Variable 'conv2d_transpose_3/kernel:0' shape=(5, 5, 3, 32) dtype=float32>]
WARNING:tensorflow:From C:\Users\alexd\AppData\Local\Temp/ipykernel_14008/1814071083.py:1: _CollectiveAllReduceStrategyExperimental.__init__ (from tensorflow.python.distribute.collective_all_reduce_strategy) is deprecated and will be removed in a future version.
Instructions for updating:
use distribute.MultiWorkerMirroredStrategy instead
WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.
INFO:tensorflow:Single-worker MultiWorkerMirroredStrategy with local_devices = ('/device:GPU:0',), communication = CommunicationImplementation.AUTO
Training Start...
Epoch : 0
Training step
Generator for noise
Discriminator ca
Generator called
gen_loss : Tensor("binary_crossentropy/weighted_loss/value:0", shape=(), dtype=float32)
disc_loss : Tensor("add:0", shape=(), dtype=float32)
WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.
INFO:tensorflow:Single-worker MultiWorkerMirroredStrategy with local_devices = ('/device:GPU:0',), communication = CommunicationImplementation.AUTO
Training Start...
Epoch : 0
Training step
Generator for noise
Discriminator for images
Discriminator for noise
gen_loss : Tensor("binary_crossentropy/weighted_loss/value:0", shape=(), dtype=float32)
disc_loss : Tensor("add:0", shape=(), dtype=float32)
cuda_malloc_async